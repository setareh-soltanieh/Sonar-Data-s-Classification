# -*- coding: utf-8 -*-
"""Sonar_data_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1--4oRCnHvXFUpDMIIpXWq5RoomaFqKfn
"""

import numpy as np
import pandas as pd 
import cv2
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.utils import np_utils
from keras.layers.core import Dense
from sklearn.metrics import confusion_matrix , classification_report
import itertools

my_file_data = []
f = open("sonar.all-data", "r")
for line in f.readlines():
    my_file_data.append(line) 
f.close()

x_sonar = []
y_sonar = []
count_R = 0
count_M = 0
for i in range(len(my_file_data)):
  x = my_file_data[i].split(",")
  float_x = []
  for j in range(len(x)):
    if x[j] == 'R\n':
      y_sonar.append(1)  
      count_R += 1
    elif x[j] == 'M\n':  
      y_sonar.append(0)
      count_M += 1
    else:  
      float_x.append(np.float(x[j])) 
  x_sonar.append(float_x)

print(count_R, count_M)

X_sonar = np.array(x_sonar)

from imblearn.over_sampling import SMOTE
# transform the dataset
oversample = SMOTE()
X_sonar, y_sonar = oversample.fit_resample(X_sonar, y_sonar)

X_train, X_test, y_train, y_test = train_test_split(X_sonar, y_sonar, test_size=0.2, random_state=27)

print(len(X_test), len(X_test[0]))

# convert labels to one-hot vectors
from keras.utils import np_utils
Y_train = np_utils.to_categorical(y_train)
Y_test = np_utils.to_categorical(y_test)

# Functions
def plot_metrics(history):

  # Plotting Metrics
  # Plot the Accuracy Curves
  fig = plt.figure()
  plt.plot(history.history['accuracy'],'r')
  plt.plot(history.history['val_accuracy'],'b')
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'], loc='lower right')
  plt.grid()

  # Plot the Loss Curves
  fig = plt.figure()
  plt.plot(history.history['loss'],'r')
  plt.plot(history.history['val_loss'],'b')
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['train', 'validation'], loc='upper right')
  plt.grid()  

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.figure(figsize = (5,5))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')    

def evaluate_model(X_test, Y_test):
  # Prediction Labels
  Y_pred = model.predict(X_test)
  y_pred = np.argmax(Y_pred, axis=1)

  # Evaluate the trained model
  [test_loss, test_acc] = model.evaluate(X_test, Y_test)
  print("Test Loss", test_loss)
  print("Test Accuracy", test_acc)

  correct_indices = np.nonzero(y_pred == y_test)[0]
  incorrect_indices = np.nonzero(y_pred != y_test)[0]

  print(" classified correctly", len(correct_indices))
  print(" classified incorrectly", len(incorrect_indices))

  # Confusion Matrix
  class_names=[0,1]
  confusion_mtx = confusion_matrix(y_test, y_pred)
  print("confusion matrix=\n",confusion_mtx)
  plot_confusion_matrix(confusion_mtx, class_names)
  print(classification_report(y_test,y_pred))

model = Sequential()
model.add(Dense(10, activation='relu', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='relu'))	#Hidden Layer 2
model.add(Dense(200, activation='relu'))	#Hidden Layer 3
model.add(Dense(300, activation='relu'))	#Hidden Layer 4
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_1 = model.fit(X_train, Y_train, epochs=50, batch_size=10, validation_split=0.2)

plot_metrics(history_1)

evaluate_model(X_test, Y_test)

"""batch = 32"""

model = Sequential()
model.add(Dense(10, activation='relu', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='relu'))	#Hidden Layer 2
model.add(Dense(200, activation='relu'))	#Hidden Layer 3
model.add(Dense(300, activation='relu'))	#Hidden Layer 4
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_2 = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2)

plot_metrics(history_2)

evaluate_model(X_test, Y_test)

"""batch size = 64"""

model = Sequential()
model.add(Dense(10, activation='relu', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='relu'))	#Hidden Layer 2
model.add(Dense(200, activation='relu'))	#Hidden Layer 3
model.add(Dense(300, activation='relu'))	#Hidden Layer 4
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_3 = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2)

plot_metrics(history_3)

evaluate_model(X_test, Y_test)

"""batch size = 128"""

model = Sequential()
model.add(Dense(10, activation='relu', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='relu'))	#Hidden Layer 2
model.add(Dense(200, activation='relu'))	#Hidden Layer 3
model.add(Dense(300, activation='relu'))	#Hidden Layer 4
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_4 = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2)

plot_metrics(history_4)

evaluate_model(X_test, Y_test)

"""batch size = 32, activation function = sigmoid"""

model = Sequential()
model.add(Dense(10, activation='sigmoid', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='sigmoid'))	#Hidden Layer 2
model.add(Dense(200, activation='sigmoid'))	#Hidden Layer 3
model.add(Dense(300, activation='sigmoid'))	#Hidden Layer 4
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_5 = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2)

plot_metrics(history_5)

evaluate_model(X_test, Y_test)

"""batch size = 32, activation function = tanh"""

model = Sequential()
model.add(Dense(10, activation='tanh', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='tanh'))	#Hidden Layer 2
model.add(Dense(200, activation='tanh'))	#Hidden Layer 3
model.add(Dense(300, activation='tanh'))	#Hidden Layer 4
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_6 = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2)

plot_metrics(history_6)

evaluate_model(X_test, Y_test)

"""Adding layers"""

model = Sequential()
model.add(Dense(10, activation='relu', input_shape=(60,)))	#Hidden Layer 1
model.add(Dense(100, activation='relu'))	#Hidden Layer 2
model.add(Dense(200, activation='relu'))	#Hidden Layer 3
model.add(Dense(300, activation='relu'))	#Hidden Layer 4
model.add(Dense(400, activation='relu'))	#Hidden Layer 5
model.add(Dense(500, activation='relu'))	#Hidden Layer 6
model.add(Dense(2, activation='linear')) #Last layer with one output per class
model.summary()

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])

history_7 = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2)

plot_metrics(history_7)

evaluate_model(X_test, Y_test)